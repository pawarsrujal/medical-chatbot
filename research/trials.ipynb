{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588c25fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sruja\\\\medical-chatbot\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a32ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a00a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sruja\\\\medical-chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de173d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sruja\\medical-chatbot\\chat\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e324342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    loader=DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "    return documents\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3641709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03341a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e50f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs\n",
    "filtered_data = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d5b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b33fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4505"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c7a1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(filtered_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=50,\n",
    "       \n",
    "    )\n",
    "\n",
    "    texts_chunk=text_splitter.split_documents(filtered_data)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb5b9797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20993"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_chunk=text_split(filtered_data)\n",
    "\n",
    "len(texts_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e900ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        \n",
    "    )\n",
    "    return embeddings\n",
    "embedding = download_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "314de0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv  \n",
    "import os\n",
    "\n",
    "# Reload environment variables to get the new HuggingFace token\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5df01747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone API Key loaded: pcsk_75aS7x_SyajQGMG...\n",
      "✅ OpenAI API Key loaded: sk-proj-O31Ko81fr5EI...\n",
      "✅ HuggingFace Token loaded: hf_ZPoOwuhqJDrYqVIiC...\n"
     ]
    }
   ],
   "source": [
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = huggingface_token\n",
    "\n",
    "print(f\"✅ Pinecone API Key loaded: {pinecone_api_key[:20]}...\")\n",
    "print(f\"✅ OpenAI API Key loaded: {openai_api_key[:20]}...\")\n",
    "print(f\"✅ HuggingFace Token loaded: {huggingface_token[:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87e76be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key=pinecone_api_key\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c532d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x23cfc597090>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d40d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "index_name = \"medical-chatbot-index\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66ee9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ WARNING: Only run this cell ONCE to upload vectors to Pinecone\n",
    "# This will upload all text chunks and may take a long time\n",
    "# After running once, skip this cell and use the next cell to load existing index\n",
    "\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# \n",
    "# docsearch = PineconeVectorStore.from_documents(\n",
    "#     documents=texts_chunk,\n",
    "#     embedding=embedding,\n",
    "#     index_name=index_name\n",
    "# )\n",
    "# \n",
    "# print(\"✅ Vectors uploaded to Pinecone successfully!\")\n",
    "\n",
    "# ⚠️ THIS CELL IS COMMENTED OUT - USE NEXT CELL TO LOAD EXISTING INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f861f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to existing Pinecone index: medical-chatbot-index\n",
      "✅ Ready to perform similarity search!\n"
     ]
    }
   ],
   "source": [
    "# ✅ USE THIS CELL - Load the existing index (doesn't re-upload vectors)\n",
    "from langchain_pinecone import PineconeVectorStore  \n",
    "\n",
    "docsearch = PineconeVectorStore(\n",
    "    embedding=embedding, \n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "print(f\"✅ Connected to existing Pinecone index: {index_name}\")\n",
    "print(\"✅ Ready to perform similarity search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fa7ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39b38937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HuggingFace InferenceClient configured and get_answer function is ready.\n"
     ]
    }
   ],
   "source": [
    "# Using a direct API call with InferenceClient for reliability\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# The API token should be loaded from .env file\n",
    "client = InferenceClient(token=huggingface_token)\n",
    "\n",
    "def get_answer(context, question):\n",
    "    \"\"\"\n",
    "    Uses the InferenceClient to get an answer from the LLM.\n",
    "    \"\"\"\n",
    "    # Create a prompt from the system message, context, and question\n",
    "    system_message = (\n",
    "        \"You are a medical assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"{system_message}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.text_generation(\n",
    "            prompt,\n",
    "            model=\"google/flan-t5-large\",\n",
    "            max_new_tokens=250,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling HuggingFace API: {e}\")\n",
    "        return \"Sorry, I could not get an answer from the model.\"\n",
    "\n",
    "print(\"✅ HuggingFace InferenceClient configured and get_answer function is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01a82c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking: 'What is Allergic rhinitis?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sruja\\AppData\\Local\\Temp\\ipykernel_11444\\3671802705.py:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieved Context ---\n",
      "Context 1 (from data\\the-gale-encyclopedia-of-medicine_compress_compressed.pdf):\n",
      "caused by allergic reaction to airborne substances.\n",
      "Description\n",
      "Allergic rhinitis (AR) is the most common allergic\n",
      "condition and one of the most common of all minor\n",
      "afflictions. It affects between 10-20% of all people in the\n",
      "United States, and is responsible for 2.5% of all doctor\n",
      "visits.Antihistaminesand other drugs used to treat aller-\n",
      "gic rhinitis make up a significant fraction of both\n",
      "prescription and over-the-counter drug sales each year.\n",
      "There are two types of allergic rhinitis: seasonal\n",
      "and perennial. Seasonal AR occurs in the spring, sum-\n",
      "mer, and early fall, when airborne plant pollens are at\n",
      "their highest levels. In fact, the term hayfever is really\n",
      "a misnomer, since allergy to grass pollen is only one\n",
      "cause of symptoms for most people. Perennial AR\n",
      "occurs all year and is usually caused by home or work-\n",
      "place airborne pollutants. A person can be affected\n",
      "by one or both types. Symptoms of seasonal AR are\n",
      "worst after being outdoors, while symptoms of peren-\n",
      "\n",
      "Context 2 (from data\\the-gale-encyclopedia-of-medicine_compress_compressed.pdf):\n",
      "nial AR are worst after spending time indoors.\n",
      "Both types ofallergies can develop at any age,\n",
      "although onset in childhood through early adulthood\n",
      "is most common. Although allergy to a particular\n",
      "substance is not inherited, increased allergic sensitivity\n",
      "may ‘‘run in the family.’’ While allergies can improve\n",
      "on their own over time, they can also become worse\n",
      "over time.\n",
      "Causes and symptoms\n",
      "Causes\n",
      "Allergic rhinitis is a type of immune reaction.\n",
      "Normally, the immune system responds to foreign\n",
      "This illustration depicts excessive mucus production in the\n",
      "nose after inhalation of airborne pollen. (Photo Researchers,\n",
      "Inc. Reproduced by permission.)\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 117\n",
      "Allergic rhinitis\n",
      "\n",
      "Context 3 (from data\\the-gale-encyclopedia-of-medicine_compress_compressed.pdf):\n",
      "Allergic rhinitis is commonly triggered by\n",
      "exposure to household dust, animal fur,\n",
      "or pollen. The foreign substance that\n",
      "triggers an allergic reaction is called\n",
      "an allergen.\n",
      "The presence of an allergen causes the\n",
      "body's lymphocytes to begin producing\n",
      "IgE antibodies. The lymphocytes of an \n",
      "allergy sufferer produce an unusually\n",
      "large amount of IgE.\n",
      "IgE molecules attach to mast\n",
      "cells, which contain histamine.\n",
      "Histamine\n",
      "Pollen grains\n",
      "Lymphocyte\n",
      "FIRST EXPOSURE\n",
      "IgE\n",
      "The allergic response. (Illustration by Hans & Cassady.)\n",
      "In a future exposure to the same substance,\n",
      "the antibodies on the mast cells bind to the\n",
      "allergens, and the cells release their histamine.Histamine travels to receptor sites in the nasal\n",
      "passages. When histamine molecules enter the\n",
      "sites they trigger dilation of the blood vessels,\n",
      "swelling, irritation, and increased production\n",
      "of mucus.\n",
      "Antihistamine drugs block histamine molecules\n",
      "from entering receptor sites, thus preventing or\n",
      "reducin\n",
      "\n",
      "\n",
      "--- Answer from RAG chain ---\n",
      "Error calling HuggingFace API: \n",
      "Sorry, I could not get an answer from the model.\n"
     ]
    }
   ],
   "source": [
    "# Manually ask a question to test the RAG chain\n",
    "question = \"What is Allergic rhinitis?\"\n",
    "print(f\"Asking: '{question}'\")\n",
    "\n",
    "# 1. Retrieve context from Pinecone\n",
    "try:\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    print(\"\\n--- Retrieved Context ---\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        print(f\"Context {i+1} (from {source}):\\n{doc.page_content}\\n\")\n",
    "\n",
    "    # 2. Get answer from the model using the retrieved context\n",
    "    print(\"\\n--- Answer from RAG chain ---\")\n",
    "    final_answer = get_answer(context, question)\n",
    "    print(final_answer)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the RAG process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577597f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
